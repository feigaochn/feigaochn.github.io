<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>Notes on Machine Learning at Coursera, Week 1</title>
        <link rel="stylesheet" href="/theme/css/main.css" />

        <!--[if IE]>
            <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">feigao.me </a></h1>
                <nav><ul>
                    <li><a href="/pages/about-me.html">about me</a></li>
                    <li class="active"><a href="/category/posts.html">posts</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/coursera-machine-learning-week-1.html" rel="bookmark"
           title="Permalink to Notes on Machine Learning at Coursera, Week 1">Notes on Machine Learning at Coursera, Week 1</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2014-07-03T16:31:00+08:00">
                Published: Thu 03 July 2014
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/fei-gao.html">Fei Gao</a>
        </address>
<p>In <a href="/category/posts.html">posts</a>. </p>
<p>tags: <a href="/tag/ml.html">ml</a> <a href="/tag/coursera.html">coursera</a> </p>
</footer><!-- /.post-info -->      <p>Start to take the famous <a href="https://www.coursera.org/course/ml">Machine Learning</a> course on Coursera. So these will be a series of study notes.</p>
<p>About the Course:</p>
<blockquote>
<p>Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.</p>
</blockquote>
<!--more-->

<p>Chinese introduction from <a href="http://mooc.guokr.com/course/16/Machine-Learning/">MOOC</a> at <a href="http://www.guokr.com">Guokr</a>:</p>
<blockquote>
<p>机器学习是一种让计算机在没有事先明确地编程的情况下做出正确反应的科学。在过去的十年中,机器学习已经给我们在自动驾驶汽车,实用语音识别,有效的网络搜索,以及提高人类基因组的认识方面带来大量帮助。今天的机器学习是如此普遍,你可能使用它每天几十次却不了解它。许多研究人员也认为这是最好的达到真正的“人工智能”的方法。在这节课,你将学习最有效的机器学习技术,获得实践并应用这种技术为自己服务的经验。最后,你将了解一些硅谷的创新的最佳实践,因为它属于机器学习和人工智能。</p>
</blockquote>
<h2>Introduction (Week 1)</h2>
<h3>What is Machine Learning</h3>
<ul>
<li>Definition</li>
</ul>
<blockquote>
<p>Tom Mitchell (1998):</p>
<p>A computer program is said to <strong>learn</strong> from <em>experience</em> E with respect to some <em>task</em> T and some <em>performance measure</em> P, if its performance on T, as measured by P, improves with experience E.</p>
</blockquote>
<ul>
<li>
<p>Algorithms:</p>
<ul>
<li>Supervised learning</li>
<li>Unsupervised learning</li>
</ul>
</li>
<li>
<p>Others:</p>
<ul>
<li>Reinforcement learning</li>
<li>Recommender systems</li>
</ul>
</li>
<li>Also talk about: practical advice for applying learning algorithms</li>
</ul>
<h3>Supervised Learning</h3>
<ul>
<li>
<p>Supervised Learning: <strong>right answers</strong> given</p>
<ul>
<li>Regression: predict continuous valued output</li>
<li>Classification: discrete valued output</li>
</ul>
</li>
</ul>
<h3>Unsupervised Learning</h3>
<ul>
<li>
<p>Clustering</p>
</li>
<li>
<p>Applications:</p>
<ul>
<li>organize computing clusters</li>
<li>social network analysis</li>
<li>market segmentation</li>
<li>astronomical data analysis</li>
</ul>
</li>
<li>
<p>Cocktail party problem algorithm</p>
</li>
</ul>
<div class="highlight"><pre>[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&#39;);
</pre></div>


<h2>Linear Regression with One Variable (Week 1)</h2>
<h3>Model Representation</h3>
<ul>
<li>Supervised learning:<ul>
<li>given the <em>right answer</em> for each example in the data</li>
</ul>
</li>
<li>Regression problem:<ul>
<li>predict <em>real-valued</em> output</li>
</ul>
</li>
<li>Classification problem:<ul>
<li>predict <em>discrete-valued</em> output</li>
</ul>
</li>
</ul>
<h4>Example: housing prices vs. sizes</h4>
<ul>
<li>Notations:<ul>
<li>$m$ = number of training examples</li>
<li>$x$ = input variable / features</li>
<li>$y$ = output variable / <em>target</em> variable</li>
</ul>
</li>
<li>Building model<ol>
<li>Training set</li>
<li>Learning algorithm</li>
<li>function $h$ named Hypothesis<ul>
<li>input: $x$</li>
<li>output: $y$</li>
</ul>
</li>
</ol>
</li>
<li>How to represent $h$?
$$ h_\theta(x) = \theta_0 + \theta_1 x $$</li>
</ul>
<h3>Cost Function</h3>
<ul>
<li>Hypothesis: $h_\theta(x) = \theta_0 + \theta_1 x$<ul>
<li>$\theta_i$'s: parameters</li>
</ul>
</li>
<li>How to choose parameters?<ul>
<li>idea: choose $\theta$'s so that $h(x)$ is close to $y$ for training examples $(x, y)$</li>
</ul>
</li>
<li>Cost function:</li>
</ul>
<p>$$\min_{\theta_0, \theta_1} J(\theta_0, \theta_1) = \frac{1}{2m} \sum_i (h_\theta (x^i) - y^i)^2$$</p>
<p>Intuition</p>
<ul>
<li>Assume $\theta_0 = 0$, then $J(\theta_1)$ is a quadratic equation.</li>
<li>Assume both $\theta$'s, the figure is bowl-like (convex).</li>
</ul>
<h3>Gradient Descent</h3>
<p>Have some function $J(\theta)$,  Want $\min_\theta J(\theta)$.</p>
<p>Outline:</p>
<ul>
<li>Start with some $\theta$</li>
<li>Keep changing $\theta$ to reduce $J(\theta)$ until we hopefully end up at a minimum</li>
</ul>
<p>Algorithm:</p>
<ul>
<li>Repeat until convergence: $$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)$$<ul>
<li>$\alpha$: learning rate (always positive)</li>
<li>$\partial J / \partial \theta_j$: derivative</li>
<li>Correct: simultaneous update all $j$.</li>
</ul>
</li>
</ul>
<p>Intuition</p>
<ul>
<li>derivative: direction of step</li>
<li>learning rate: length of step</li>
</ul>
<p>Gradient descent can converge to a <em>local minimum</em>, even with the learning rate $\alpha$ fixed. As we approach a local minimum, gradient descent will automatically take smaller steps. So, no need to decrease $\alpha$ over time.</p>
<h4>Gradient descent for linear regression</h4>
<ul>
<li>convex: one global minimum</li>
<li>"Batch" Gradient Descent: each step of gradient descent uses all the training examples</li>
<li>Numerical solution for gradient</li>
<li>Faster than normal equation method for larger data set</li>
</ul>
<h3>What's Next</h3>
<p>Two extension:</p>
<ol>
<li>Solve for $\theta$ exactly, without needing iterative algorithm</li>
<li>Learn with larger number of features</li>
</ol>
<h2>Linear Algebra Review (Week 1, Optional)</h2>
<p>Pass</p>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>blogroll</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="https://twitter.com/feigaochn">Twitter</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>